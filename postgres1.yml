scope: batman
#namespace: /service/
name: postgresql1

restapi:
  listen: 127.0.0.1:8009
  connect_address: 127.0.0.1:8009
#  cafile: /etc/ssl/certs/ssl-cacert-snakeoil.pem
#  certfile: /etc/ssl/certs/ssl-cert-snakeoil.pem
#  keyfile: /etc/ssl/private/ssl-cert-snakeoil.key
#  authentication:
#    username: username
#    password: password

#ctl:
#  insecure: false # Allow connections to Patroni REST API without verifying certificates
#  certfile: /etc/ssl/certs/ssl-cert-snakeoil.pem
#  keyfile: /etc/ssl/private/ssl-cert-snakeoil.key
#  cacert: /etc/ssl/certs/ssl-cacert-snakeoil.pem

#citus:
#  database: citus
#  group: 1  # worker

etcd:
  #Provide host to do the initial discovery of the cluster topology:
  host: 127.0.0.1:2379
  #Or use "hosts" to provide multiple endpoints
  #Could be a comma separated string:
  #hosts: host1:port1,host2:port2
  #or an actual yaml list:
  #hosts:
  #- host1:port1
  #- host2:port2
  #Once discovery is complete Patroni will use the list of advertised clientURLs
  #It is possible to change this behavior through by setting:
  #use_proxies: true

#raft:
#  data_dir: .
#  self_addr: 127.0.0.1:2223
#  partner_addrs:
#  - 127.0.0.1:2222
#  - 127.0.0.1:2224

bootstrap:
  # this section will be written into Etcd:/<namespace>/<scope>/config after initializing new cluster
  # and all other cluster members will use it as a `global configuration`
  dcs:
    ttl: 30
    loop_wait: 10
    retry_timeout: 10
    maximum_lag_on_failover: 1048576
    postgresql:
      use_pg_rewind: false
      pg_hba:
      # For kerberos gss based connectivity (discard @.*$)
      #- host replication replicator 127.0.0.1/32 gss include_realm=0
      #- host all all 0.0.0.0/0 gss include_realm=0
      - host replication replicator 127.0.0.1/32 md5
      - host all all 0.0.0.0/0 md5
      #  - hostssl all all 0.0.0.0/0 md5
#      use_slots: true
      parameters:
        wal_level: hot_standby
        hot_standby: 'on'
        max_connections: '443'
        max_replication_slots: '999'
        max_wal_senders: '999'
        max_worker_processes: '8'
        wal_level: logical
        archive_mode: "on"
        archive_timeout: 1800s
        archive_command: mkdir -p ../wal_archive && test ! -f ../wal_archive/%f && cp %p ../wal_archive/%f && sleep 1
        autovacuum: 'on'
        autovacuum_analyze_scale_factor: '0.01'
        autovacuum_max_workers: '5'
        autovacuum_vacuum_scale_factor: '0.05'
        default_statistics_target: '500'
        effective_io_concurrency: '100'
        fsync: 'on'
        hot_standby_feedback: 'on'
        idle_in_transaction_session_timeout: 15min
        idle_session_timeout: 24h
        log_autovacuum_min_duration: 5s
        log_checkpoints: 'on'
        log_connections: 'on'
        log_directory: ../pg_log
        log_disconnections: 'off'
        log_file_mode: '0644'
        log_line_prefix: '%m [%p] %q%a %u@%d %r '
        log_lock_waits: 'on'
        log_min_duration_sample: 500ms
        log_rotation_age: 1d
        log_rotation_size: 512MB
        log_statement: ddl
        log_statement_sample_rate: '0.05'
        logging_collector: 'on'
        max_parallel_workers: '8'
        max_wal_size: 8GB
        password_encryption: scram-sha-256
        pg_stat_statements.max: '10000'
        pg_stat_statements.track: all
        pg_stat_statements.track_utility: 'off'
        random_page_cost: '1.1'
        seq_page_cost: '1.0'
        statement_timeout: 5s
        tcp_keepalives_idle: '900'
        tcp_keepalives_interval: '100'
        track_activities: 'on'
        track_activity_query_size: '4096'
        track_functions: all
        track_io_timing: 'on'
        wal_buffers: 64MB
        wal_compression: 'on'
      # recovery_conf:
      #   restore_command: cp ../wal_archive/%f %p

  # some desired options for 'initdb'
  initdb:  # Note: It needs to be a list (some options need values, others are switches)
  - encoding: UTF8
  - data-checksums
  - encoding: UTF8
  - locale: en_US.UTF-8
  - wal-segsize: '64'
  post_init: /scripts/post_init.sh "dre"

  # Additional script to be launched after initial cluster creation (will be passed the connection URL as parameter)
# post_init: /usr/local/bin/setup_cluster.sh

  # Some additional users users which needs to be created after initializing new cluster
  users:
    admin:
      password: admin%
      options:
        - createrole
        - createdb

postgresql:
  listen: 127.0.0.1:5433
  connect_address: 127.0.0.1:5433
#  proxy_address: 127.0.0.1:5434  # The address of connection pool (e.g., pgbouncer) running next to Patroni/Postgres. Only for service discovery.
  data_dir: data/postgresql1
#  bin_dir:
#  config_dir:
  pgpass: /tmp/pgpass1
  authentication:
    replication:
      username: replicator
      password: rep-pass
    superuser:
      username: postgres
      password: zalando
    rewind:  # Has no effect on postgres 10 and lower
      username: rewind_user
      password: rewind_password
  # Server side kerberos spn
#  krbsrvname: postgres
  parameters:
    # Fully qualified kerberos ticket file for the running user
    # same as KRB5CCNAME used by the GSS
#    krb_server_keyfile: /var/spool/keytabs/postgres
    unix_socket_directories: '..'  # parent directory of data_dir
  basebackup:
      - verbose
      - max-rate: 100M
#      - waldir: /pg-wal-mount/external-waldir # only needed in case pg_wal is symlinked outside of data_dir
  # Additional fencing script executed after acquiring the leader lock but before promoting the replica
  #pre_promote: /path/to/pre_promote.sh

tags:
    nofailover: false
    noloadbalance: false
    clonefrom: false
